# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/154siV9U8kYqLPVALi5Kackci00agbDvr
"""

import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class DNADataset(Dataset):
    def __init__(self, sequences, labels, tokenizer, max_length=512):
        self.sequences = [seq.split() for seq in sequences]  
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        seq = self.sequences[idx]
        label = self.labels[idx]
        encoding = self.tokenizer(
            seq,
            is_split_into_words=True,
            padding='max_length',
            truncation=True,
            max_length=self.max_length,
            return_tensors='pt'
        )
        item = {key: val.squeeze(0) for key, val in encoding.items()}
        item['labels'] = torch.tensor(label, dtype=torch.long)
        return item

tokenizer = AutoTokenizer.from_pretrained("zhihan1996/DNA_bert_6", trust_remote_code=True)

model_path = "/content/drive/MyDrive/dna_bert_epoch3.pth"
model = AutoModelForSequenceClassification.from_pretrained(
    "zhihan1996/DNA_bert_6",
    trust_remote_code=True,
    num_labels=2
)

state_dict = torch.load(model_path, map_location="cpu")  
model.load_state_dict(state_dict)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

df = pd.read_csv("/content/drive/MyDrive/cutoff0.3/dev.csv")
sequences = df['sequence'].tolist()
labels = df['label'].tolist()

dev_dataset = DNADataset(sequences, labels, tokenizer, max_length=512)
dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)
model.eval()

sample_indices = random.sample(range(len(dev_loader.dataset)), 3)

for idx in sample_indices:
    sample = dev_loader.dataset[idx]
    input_ids = sample['input_ids'].unsqueeze(0).to(device)
    attention_mask = sample['attention_mask'].unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(input_ids=input_ids,
                        attention_mask=attention_mask,
                        output_attentions=True)  
        attentions = outputs.attentions  

last_layer_attn = attentions[-1][0].cpu()  
num_heads = last_layer_attn.shape[0]

for head in range(num_heads):
  plt.figure(figsize=(8,6))
  sns.heatmap(last_layer_attn[head].numpy(), cmap='viridis')
  plt.title(f'Sample {idx} - Head {head} Attention')
  plt.xlabel('Token Position')
  plt.ylabel('Token Position')
  plt.show()

