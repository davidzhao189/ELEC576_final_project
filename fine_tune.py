# -*- coding: utf-8 -*-
"""fine_tune.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XRe33q4Vmx-RC4Ug5bopDDFdONOHLfSJ
"""

#balancing training data
import pandas as pd
from sklearn.utils import resample

train_csv = "/content/drive/MyDrive/rice_project/ENC003.HeartLeftVentricle/train.csv"
df = pd.read_csv(train_csv)

df_positive = df[df['label'] == 1]
df_negative = df[df['label'] == 0]

n_samples = min(len(df_positive), len(df_negative))
df_positive_down = resample(df_positive, n_samples=n_samples, replace=False, random_state=42)
df_negative_down = resample(df_negative, n_samples=n_samples, replace=False, random_state=42)

df_balanced = pd.concat([df_positive_down, df_negative_down]).sample(frac=1, random_state=42)  # shuffle

df_balanced.to_csv("/content/ENC003.HeartLeftVentricle/cutoff0.3/train_balanced.csv", index=False)

import torch
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DEVICE

import os
import csv
import torch
from torch.utils.data import Dataset, DataLoader
from torch.nn import CrossEntropyLoss
from torch.optim import AdamW
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

global_step = 0
class DNADataset(Dataset):
    def __init__(self, csv_path, tokenizer, max_length=512):
        self.texts = []
        self.labels = []
        with open(csv_path, "r") as f:
            reader = csv.reader(f)
            next(reader)  # skip header
            for row in reader:
                seq = row[0].strip()
                label = int(row[1])
                if len(seq) == 0:
                    continue
                self.texts.append(seq)
                self.labels.append(label)

        self.encodings = tokenizer(
            self.texts,
            padding=True,
            truncation=True,
            max_length=max_length,
            return_tensors="pt"
        )

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

MODEL_NAME = "zhihan1996/DNA_bert_6"
TRAIN_CSV = "/content/cutoff0.3/train.csv"
DEV_CSV = "/content/cutoff0.3/dev.csv"
BATCH_SIZE = 32
EPOCHS = 10
LR = 5e-5
MAX_LENGTH = 100
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME, num_labels=2, trust_remote_code=True
)
model.to(DEVICE)

train_dataset = DNADataset(TRAIN_CSV, tokenizer, max_length=MAX_LENGTH)
dev_dataset = DNADataset(DEV_CSV, tokenizer, max_length=MAX_LENGTH)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False)

optimizer = AdamW(model.parameters(), lr=LR)
criterion = CrossEntropyLoss()

for epoch in range(EPOCHS):
    model.train()
    epoch_loss = 0
    step_loss = 0
    for batch in train_loader:
        optimizer.zero_grad()
        input_ids = batch['input_ids'].to(DEVICE)
        attention_mask = batch['attention_mask'].to(DEVICE)
        labels = batch['labels'].to(DEVICE)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()

        global_step += 1
        epoch_loss += loss.item()
        step_loss += loss.item()

        if global_step % 2000 == 0:
            avg_step_loss = step_loss / 2000
            print(f"Step {global_step}, Avg Train Loss (last 2000 steps): {avg_step_loss:.4f}")
            step_loss = 0 

    avg_epoch_loss = epoch_loss / len(train_loader)
    print(f"Epoch {epoch+1}/{EPOCHS}, Avg Train Loss (epoch): {avg_epoch_loss:.4f}")

    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for batch in dev_loader:
            input_ids = batch['input_ids'].to(DEVICE)
            attention_mask = batch['attention_mask'].to(DEVICE)
            labels = batch['labels'].to(DEVICE)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            preds = torch.argmax(outputs.logits, dim=-1)

            all_preds.extend(preds.cpu().tolist())
            all_labels.extend(labels.cpu().tolist())

    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='macro')
    prec = precision_score(all_labels, all_preds, average='macro')
    rec = recall_score(all_labels, all_preds, average='macro')

    print(f"Validation -> Acc: {acc:.4f}, F1: {f1:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}")

    save_dir = "/content/drive/MyDrive/DNA_BERT_models/cutoff0.3_balanced_STL003.Left_Ventricle"
    os.makedirs(save_dir, exist_ok=True)

    save_path = os.path.join(save_dir, f"dna_bert_epoch{epoch+1}.pth")
    torch.save(model.state_dict(), save_path)
    print(f"Model saved to {save_path}")

